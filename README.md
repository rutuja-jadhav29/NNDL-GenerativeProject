# NNDL-GenerativeProject

## Text-to-Image Generation Using Stable Diffusion

A comprehensive implementation and evaluation of text-to-image generation using Stable Diffusion v1.5 and CLIP text encoders. This project demonstrates the complete pipeline from dataset preparation through model evaluation with multiple quantitative metrics.


## Project Structure
```
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ flickr30k/
â”‚       â”œâ”€â”€ cleaned_images/
â”‚       â””â”€â”€ cleaned_captions.csv
â”‚
â”œâ”€â”€ milestone1/
â”‚   â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ baseline_text_to_embedding.ipynb
â”‚   â”œâ”€â”€ E7615_Project2-Milestone1.pdf
â”‚   â”œâ”€â”€ preprocess_flickr30k.py
â”‚   â””â”€â”€ validate_clip_alignment.py
â”‚
â”œâ”€â”€ milestone2/
â”‚   â”œâ”€â”€ M2_Outputs/
â”‚   â”œâ”€â”€ Generative_Project_Milestone2.ipynb
â”‚   â”œâ”€â”€ Milestone_2_Generative_project.ipynb
â”‚   â””â”€â”€ training_log.csv
â”‚
â”œâ”€â”€ milestone3/
â”‚   â”œâ”€â”€ Art_Styles.ipynb
â”‚   â”œâ”€â”€ Generative_Project_Milestone3.ipynb
â”‚   â””â”€â”€ Milestone3Final.ipynb
â”‚
â”œâ”€â”€
â”‚   â”œâ”€â”€ NNDL_FinalPPt.pptx
â”‚   â””â”€â”€ Report_NNDL.pdf
â”‚
â””â”€â”€ .git/


```

## Installation

### Prerequisites

- Python 3.8 or higher

- CUDA-capable GPU (recommended for training/generation)

- 16GB+ RAM

10GB+ free disk space

## Setup

### 1. Clone the repository and 
```
git clone https://github.com/rutuja-jadhav29/NNDL-GenerativeProject.git
   cd NNDL-GenerativeProject
```

2. Create virtual environment
```
python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
 ```

3. Install dependencies
```
pip install -r requirements.txt
```

## Dataset

### Flickr30k Dataset

We use the Flickr30k dataset containing 31,000 images with five captions each.
Download Instructions:

Request access to Flickr30k from the official source
Download and extract to data/flickr30k_images/
Run preprocessing script



Dataset Statistics

Total Images: 31,000

Cleaned Images: 2,879 (after removing corrupted files)

Captions per Image: 5

Image Size: 224Ã—224 pixels

Dataset Size: ~8GB (original), ~500MB (cleaned)


## Evaluation Metrics
### FrÃ©chet Inception Distance (FID)

Measures distribution similarity between real and generated images using Inception-V3 features.

Lower is better

Baseline: 404.25

Stable Diffusion: 362.79 âœ…

### Inception Score (IS)

Evaluates image quality and diversity based on classifier predictions.

Higher is better

Baseline: 1.0

Stable Diffusion: 1.3 âœ…


## Key Achievements

âœ… 10.3% FID Improvement: Stable Diffusion achieves FID of 362.79 vs 404.25 baseline

âœ… 30% IS Improvement: Inception Score increased from 1.0 to 1.3

âœ… Optimal Parameters Identified: Guidance scale 7.5 and 50 inference steps

âœ… Comprehensive Evaluation: FID, IS, and CLIP similarity metrics

âœ… Parameter Sensitivity Analysis: Guidance scale and embedding architecture comparison

## Features

ğŸ–¼ï¸ Text-to-Image Generation: Generate images from natural language prompts

ğŸ“Š Multiple Evaluation Metrics: FID, Inception Score, CLIP similarity

ğŸ”§ Parameter Tuning: Guidance scale and inference steps optimization

ğŸ“ˆ Comprehensive Logging: Training logs and result tracking

ğŸ¨ Qualitative Analysis: Side-by-side visual comparisons

ğŸ”¬ Embedding Sensitivity: CLIP ViT-B/32 vs ViT-B/16 comparison
